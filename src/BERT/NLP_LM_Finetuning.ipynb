{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ADKCnENMQdJE",
        "outputId": "c6e53652-e167-40c3-8996-be49377fda75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[K     |████████████████████████████████| 176 kB 28.6 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.24.25-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 58.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 57.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.64.0)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 30.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch-transformers) (4.1.1)\n",
            "Collecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 10.2 MB/s \n",
            "\u001b[?25hCollecting botocore<1.28.0,>=1.27.25\n",
            "  Downloading botocore-1.27.25-py3-none-any.whl (9.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.0 MB 55.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.28.0,>=1.27.25->boto3->pytorch-transformers) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.10-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 76.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.28.0,>=1.27.25->boto3->pytorch-transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2022.6.15)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 72.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.1.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=d37d754dd57620d703859ea10c3e081bf71f56499be12e15b006382b7c6f0e96\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, pytorch-transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.24.25 botocore-1.27.25 jmespath-1.0.1 pytorch-transformers-1.2.0 s3transfer-0.6.0 sacremoses-0.0.53 sentencepiece-0.1.96 urllib3-1.25.11\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install transformers\n",
        "!pip install pytorch-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuRLx3-IugqS"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_nYLYAEucNR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from tqdm import  tqdm_notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL-NKe90uf7-"
      },
      "outputs": [],
      "source": [
        "directory_path = '/content/drive/My Drive/nlp'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YidSfaHllsAH",
        "outputId": "f4b562fd-3d47-40bd-f5d2-b6cbf00b1894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqMyfhLQvfLk"
      },
      "outputs": [],
      "source": [
        "hotel_df = pd.read_csv(os.path.join(directory_path,'data_for_bert.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icA0x2dsvkfi",
        "outputId": "5f9451d7-b334-4d34-c1f4-fbbc4f229799"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31163, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "hotel_df.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K15VAxRwv49Y"
      },
      "outputs": [],
      "source": [
        "changed_text=hotel_df.preprocessed_plot.apply(lambda x:x+\"\\n\"+\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "changed_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK5J1KSqmYRG",
        "outputId": "76ca9e03-1be6-4baa-c64f-0bb67d297e52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        As a Palestinian assassin is targeting promine...\n",
              "1        A girl and her friends find a game in the atti...\n",
              "2        The Earth is invaded by stingray-shaped alien ...\n",
              "3        Józef visits his dying father at a remote ment...\n",
              "4        The life of five-time Formula One world champi...\n",
              "                               ...                        \n",
              "31158    The Chipmunks compete with the Chipettes in a ...\n",
              "31159    In 1940, the British Royal Air Force fights a ...\n",
              "31160    Who wrote this original plot??!! It makes no s...\n",
              "31161    A mysteriously linked pair of young women find...\n",
              "31162    A look at the life of real estate king/media m...\n",
              "Name: preprocessed_plot, Length: 31163, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oSgYg9hwAfq",
        "outputId": "10c26ee2-decc-41e4-e509-5f9e0f458d1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4935208"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "open(os.path.join(directory_path,'data_lm_plots.txt'), \"w\").write(''.join(changed_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBqjX0ibwEBf",
        "outputId": "c08c3a2c-b1d8-433c-9d3e-40b1225b301e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/nlp\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['data_for_bert.csv',\n",
              " 'data_lm_plots.txt',\n",
              " 'pregenerate_training_data.py',\n",
              " 'finetune_on_pregenerated.py']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "%cd /content/drive/My Drive/nlp\n",
        "import os\n",
        "os.listdir(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HErmibFVwx7D",
        "outputId": "af05a9a0-2437-430d-96b5-55a3abe63290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Dataset: 62326 lines [00:14, 4295.90 lines/s]\n",
            "Epoch:   0% 0/2 [00:00<?, ?it/s]\n",
            "Document:   0% 0/31163 [00:00<?, ?it/s]\u001b[A\n",
            "Document:   2% 748/31163 [00:00<00:04, 7476.85it/s]\u001b[A\n",
            "Document:   5% 1589/31163 [00:00<00:03, 8022.22it/s]\u001b[A\n",
            "Document:   8% 2407/31163 [00:00<00:03, 8092.94it/s]\u001b[A\n",
            "Document:  10% 3218/31163 [00:00<00:03, 8095.78it/s]\u001b[A\n",
            "Document:  13% 4028/31163 [00:00<00:03, 8019.98it/s]\u001b[A\n",
            "Document:  16% 4892/31163 [00:00<00:03, 8229.20it/s]\u001b[A\n",
            "Document:  18% 5716/31163 [00:00<00:03, 8220.78it/s]\u001b[A\n",
            "Document:  21% 6554/31163 [00:00<00:02, 8269.79it/s]\u001b[A\n",
            "Document:  24% 7427/31163 [00:00<00:02, 8412.71it/s]\u001b[A\n",
            "Document:  27% 8269/31163 [00:01<00:02, 8375.46it/s]\u001b[A\n",
            "Document:  29% 9146/31163 [00:01<00:02, 8494.68it/s]\u001b[A\n",
            "Document:  32% 10020/31163 [00:01<00:02, 8567.78it/s]\u001b[A\n",
            "Document:  35% 10877/31163 [00:01<00:02, 8415.28it/s]\u001b[A\n",
            "Document:  38% 11749/31163 [00:01<00:02, 8502.82it/s]\u001b[A\n",
            "Document:  40% 12600/31163 [00:01<00:02, 8355.92it/s]\u001b[A\n",
            "Document:  43% 13437/31163 [00:01<00:02, 8270.78it/s]\u001b[A\n",
            "Document:  46% 14305/31163 [00:01<00:02, 8388.71it/s]\u001b[A\n",
            "Document:  49% 15156/31163 [00:01<00:01, 8422.19it/s]\u001b[A\n",
            "Document:  51% 15999/31163 [00:01<00:01, 8333.56it/s]\u001b[A\n",
            "Document:  54% 16865/31163 [00:02<00:01, 8429.61it/s]\u001b[A\n",
            "Document:  57% 17709/31163 [00:02<00:01, 8309.77it/s]\u001b[A\n",
            "Document:  60% 18583/31163 [00:02<00:01, 8435.26it/s]\u001b[A\n",
            "Document:  62% 19441/31163 [00:02<00:01, 8476.91it/s]\u001b[A\n",
            "Document:  65% 20291/31163 [00:02<00:01, 8481.78it/s]\u001b[A\n",
            "Document:  68% 21140/31163 [00:02<00:01, 8197.72it/s]\u001b[A\n",
            "Document:  70% 21963/31163 [00:02<00:01, 8205.23it/s]\u001b[A\n",
            "Document:  73% 22825/31163 [00:02<00:01, 8325.20it/s]\u001b[A\n",
            "Document:  76% 23693/31163 [00:02<00:00, 8427.73it/s]\u001b[A\n",
            "Document:  79% 24547/31163 [00:02<00:00, 8457.12it/s]\u001b[A\n",
            "Document:  82% 25405/31163 [00:03<00:00, 8491.51it/s]\u001b[A\n",
            "Document:  84% 26268/31163 [00:03<00:00, 8532.44it/s]\u001b[A\n",
            "Document:  87% 27125/31163 [00:03<00:00, 8540.83it/s]\u001b[A\n",
            "Document:  90% 27980/31163 [00:03<00:00, 8513.96it/s]\u001b[A\n",
            "Document:  93% 28861/31163 [00:03<00:00, 8601.51it/s]\u001b[A\n",
            "Document:  95% 29722/31163 [00:03<00:00, 8178.75it/s]\u001b[A\n",
            "Document: 100% 31163/31163 [00:03<00:00, 8354.12it/s]\n",
            "Epoch:  50% 1/2 [00:03<00:03,  3.74s/it]\n",
            "Document:   0% 0/31163 [00:00<?, ?it/s]\u001b[A\n",
            "Document:   3% 860/31163 [00:00<00:03, 8593.08it/s]\u001b[A\n",
            "Document:   6% 1720/31163 [00:00<00:03, 8559.30it/s]\u001b[A\n",
            "Document:   8% 2591/31163 [00:00<00:03, 8625.70it/s]\u001b[A\n",
            "Document:  11% 3454/31163 [00:00<00:03, 8526.48it/s]\u001b[A\n",
            "Document:  14% 4307/31163 [00:00<00:03, 8455.88it/s]\u001b[A\n",
            "Document:  17% 5170/31163 [00:00<00:03, 8511.47it/s]\u001b[A\n",
            "Document:  19% 6038/31163 [00:00<00:02, 8564.53it/s]\u001b[A\n",
            "Document:  22% 6895/31163 [00:00<00:02, 8328.69it/s]\u001b[A\n",
            "Document:  25% 7765/31163 [00:00<00:02, 8440.11it/s]\u001b[A\n",
            "Document:  28% 8611/31163 [00:01<00:02, 8419.88it/s]\u001b[A\n",
            "Document:  30% 9454/31163 [00:01<00:02, 8363.60it/s]\u001b[A\n",
            "Document:  33% 10307/31163 [00:01<00:02, 8412.82it/s]\u001b[A\n",
            "Document:  36% 11149/31163 [00:01<00:02, 8367.83it/s]\u001b[A\n",
            "Document:  38% 11987/31163 [00:01<00:02, 8352.98it/s]\u001b[A\n",
            "Document:  41% 12823/31163 [00:01<00:02, 7905.19it/s]\u001b[A\n",
            "Document:  44% 13665/31163 [00:01<00:02, 8050.54it/s]\u001b[A\n",
            "Document:  47% 14519/31163 [00:01<00:02, 8192.17it/s]\u001b[A\n",
            "Document:  49% 15342/31163 [00:01<00:01, 8023.66it/s]\u001b[A\n",
            "Document:  52% 16192/31163 [00:01<00:01, 8159.10it/s]\u001b[A\n",
            "Document:  55% 17027/31163 [00:02<00:01, 8214.53it/s]\u001b[A\n",
            "Document:  57% 17851/31163 [00:02<00:01, 8195.56it/s]\u001b[A\n",
            "Document:  60% 18728/31163 [00:02<00:01, 8365.00it/s]\u001b[A\n",
            "Document:  63% 19581/31163 [00:02<00:01, 8412.79it/s]\u001b[A\n",
            "Document:  66% 20457/31163 [00:02<00:01, 8514.75it/s]\u001b[A\n",
            "Document:  68% 21319/31163 [00:02<00:01, 8546.05it/s]\u001b[A\n",
            "Document:  71% 22175/31163 [00:02<00:01, 8164.88it/s]\u001b[A\n",
            "Document:  74% 23054/31163 [00:02<00:00, 8343.13it/s]\u001b[A\n",
            "Document:  77% 23892/31163 [00:02<00:00, 8141.24it/s]\u001b[A\n",
            "Document:  79% 24710/31163 [00:02<00:00, 8007.09it/s]\u001b[A\n",
            "Document:  82% 25550/31163 [00:03<00:00, 8119.92it/s]\u001b[A\n",
            "Document:  85% 26377/31163 [00:03<00:00, 8163.07it/s]\u001b[A\n",
            "Document:  87% 27246/31163 [00:03<00:00, 8315.91it/s]\u001b[A\n",
            "Document:  90% 28079/31163 [00:03<00:00, 8282.58it/s]\u001b[A\n",
            "Document:  93% 28911/31163 [00:03<00:00, 8292.00it/s]\u001b[A\n",
            "Document:  96% 29786/31163 [00:03<00:00, 8427.69it/s]\u001b[A\n",
            "Document: 100% 31163/31163 [00:03<00:00, 8316.49it/s]\n",
            "Epoch: 100% 2/2 [00:07<00:00,  3.75s/it]\n"
          ]
        }
      ],
      "source": [
        "!python3 pregenerate_training_data.py --train_corpus data_lm_plots.txt --bert_model bert-base-uncased --do_lower_case --output_dir training/ --epochs_to_generate 2 --max_seq_len 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "W_em6w6RxEwQ",
        "outputId": "b99236a7-e893-4435-ffcf-ad81871bbb63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['README.md',\n",
              " 'simple_lm_finetuning.py',\n",
              " 'pregenerate_training_data.py',\n",
              " 'finetune_on_pregenerated.py',\n",
              " 'data_lm_hotel.txt',\n",
              " 'training']"
            ]
          },
          "execution_count": 71,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-q-wxugGxMkx",
        "outputId": "d84c05cc-fc19-49d3-b0e1-7beeeef3535c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-07-08 21:10:29,330: device: cuda n_gpu: 1, distributed training: False, 16-bits training: False\n",
            "2022-07-08 21:10:30,276: loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /root/.cache/torch/pytorch_transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
            "2022-07-08 21:10:31,273: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json not found in cache or force_download set to True, downloading to /tmp/tmpkafgo8vi\n",
            "100% 433/433 [00:00<00:00, 401444.22B/s]\n",
            "2022-07-08 21:10:32,239: copying /tmp/tmpkafgo8vi to cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2022-07-08 21:10:32,240: creating metadata file for /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2022-07-08 21:10:32,240: removing temp file /tmp/tmpkafgo8vi\n",
            "2022-07-08 21:10:32,240: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /root/.cache/torch/pytorch_transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
            "2022-07-08 21:10:32,240: Model config {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "2022-07-08 21:10:33,207: https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin not found in cache or force_download set to True, downloading to /tmp/tmpjqkuu659\n",
            "100% 440473133/440473133 [00:36<00:00, 12102954.45B/s]\n",
            "2022-07-08 21:11:10,634: copying /tmp/tmpjqkuu659 to cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2022-07-08 21:11:11,639: creating metadata file for /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2022-07-08 21:11:11,639: removing temp file /tmp/tmpjqkuu659\n",
            "2022-07-08 21:11:11,705: loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at /root/.cache/torch/pytorch_transformers/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
            "2022-07-08 21:11:27,844: ***** Running training *****\n",
            "2022-07-08 21:11:27,845:   Num examples = 62326\n",
            "2022-07-08 21:11:27,845:   Batch size = 16\n",
            "2022-07-08 21:11:27,845:   Num steps = 3895\n",
            "finetune_on_pregenerated.py:88: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  input_masks = np.zeros(shape=(num_samples, seq_len), dtype=np.bool)\n",
            "finetune_on_pregenerated.py:89: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  segment_ids = np.zeros(shape=(num_samples, seq_len), dtype=np.bool)\n",
            "finetune_on_pregenerated.py:91: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  is_nexts = np.zeros(shape=(num_samples,), dtype=np.bool)\n",
            "2022-07-08 21:11:27,856: Loading training examples for epoch 0\n",
            "Training examples:   0% 0/31163 [00:00<?, ?it/s]finetune_on_pregenerated.py:38: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  input_array = np.zeros(max_seq_length, dtype=np.int)\n",
            "finetune_on_pregenerated.py:41: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  mask_array = np.zeros(max_seq_length, dtype=np.bool)\n",
            "finetune_on_pregenerated.py:44: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  segment_array = np.zeros(max_seq_length, dtype=np.bool)\n",
            "finetune_on_pregenerated.py:47: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  lm_label_array = np.full(max_seq_length, dtype=np.int, fill_value=-1)\n",
            "Training examples: 100% 31163/31163 [00:03<00:00, 9413.97it/s]\n",
            "2022-07-08 21:11:31,167: Loading complete!\n",
            "Epoch 0:   0% 1/1948 [00:00<15:45,  2.06it/s, Loss: 5.92877]/usr/local/lib/python3.7/dist-packages/pytorch_transformers/optimization.py:166: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1055.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "Epoch 0: 100% 1948/1948 [14:29<00:00,  2.24it/s, Loss: 2.01698]\n",
            "2022-07-08 21:26:00,399: Loading training examples for epoch 1\n",
            "Training examples: 100% 31163/31163 [00:03<00:00, 9072.04it/s]\n",
            "2022-07-08 21:26:03,838: Loading complete!\n",
            "Epoch 1: 100% 1948/1948 [14:33<00:00,  2.23it/s, Loss: 1.87660]\n",
            "2022-07-08 21:40:37,280: ** ** * Saving fine-tuned model ** ** * \n"
          ]
        }
      ],
      "source": [
        "!python3 finetune_on_pregenerated.py --pregenerated_data training/ --bert_model bert-base-uncased --do_lower_case --train_batch_size 16  --output_dir finetuned_lm/ --epochs 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypk8HZG7xaiq"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "NLP_LM_Finetuning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}